{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b4ca7c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from src.cv.roi_detection import *\n",
    "from pathlib import Path\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "example_dir = Path(\"../data/frame_example\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07c778ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_box(img_bgr, roi, color=(0, 255, 0), thickness=2):\n",
    "    x, y, w, h = [int(v) for v in roi]\n",
    "    out = img_bgr.copy()\n",
    "    cv2.rectangle(out, (x, y), (x + w, y + h), color, thickness)\n",
    "    return out\n",
    "\n",
    "def crop_roi(img_bgr, roi):\n",
    "    x, y, w, h = [int(v) for v in roi]\n",
    "    x = max(0, x); y = max(0, y)\n",
    "    return img_bgr[y:y+h, x:x+w].copy()\n",
    "\n",
    "def overlay_mask(img_bgr, mask_u8, alpha=0.45):\n",
    "    # mask_u8: 0..255\n",
    "    if mask_u8.ndim == 2:\n",
    "        m = mask_u8\n",
    "    else:\n",
    "        m = mask_u8[..., 0]\n",
    "    m = (m > 0).astype(np.uint8) * 255\n",
    "    color = np.zeros_like(img_bgr)\n",
    "    color[..., 1] = m  # green overlay\n",
    "    return cv2.addWeighted(img_bgr, 1.0, color, alpha, 0)\n",
    "\n",
    "def overlay_red_mask(img_bgr: np.ndarray, mask: np.ndarray, alpha: float = 0.45) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Overlay a binary mask in RED over a BGR image.\n",
    "    - img_bgr: HxWx3 uint8\n",
    "    - mask: HxW (bool/0-1/0-255/labels) where anything >0 is treated as foreground\n",
    "    \"\"\"\n",
    "    if mask is None:\n",
    "        return img_bgr\n",
    "\n",
    "    if mask.ndim == 3:\n",
    "        mask = mask[..., 0]\n",
    "\n",
    "    m = (mask > 0)\n",
    "    out = img_bgr.copy()\n",
    "\n",
    "    # Red color in BGR\n",
    "    red = np.zeros_like(out, dtype=np.float32)\n",
    "    red[..., 2] = 255.0\n",
    "\n",
    "    out_f = out.astype(np.float32)\n",
    "    out_f[m] = (1.0 - alpha) * out_f[m] + alpha * red[m]\n",
    "    return np.clip(out_f, 0, 255).astype(np.uint8)\n",
    "\n",
    "\n",
    "def bgr2rgb(img_bgr):\n",
    "    return cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6c135a1-e448-49e9-a166-1871bf1e971b",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = Path(\"data/roi_example\")\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "paths = sorted([p for p in example_dir.glob(\"*\") if p.suffix.lower() in [\".png\", \".jpg\", \".jpeg\"]])\n",
    "\n",
    "for p in paths:\n",
    "    camera = p.stem  \n",
    "    img_bgr = cv2.imread(str(p), cv2.IMREAD_COLOR)\n",
    "    if img_bgr is None:\n",
    "        print(\"Could not read:\", p)\n",
    "        continue\n",
    "\n",
    "    roi_chest = detect_ROI(str(p), camera=camera, region=\"chest\")\n",
    "\n",
    "    roi_abd = detect_ROI(str(p), camera=camera, region=\"abdomen\")\n",
    "\n",
    "    boxed = img_bgr.copy()\n",
    "    boxed_chest = draw_box(boxed, roi_chest, color=(0, 0, 255), thickness=4)   \n",
    "    boxed_abd = draw_box(boxed, roi_abd,  color=(0, 0, 255), thickness=4)   \n",
    "\n",
    "    out_path_chest = out_dir / f\"{p.stem}_chest.png\"\n",
    "    cv2.imwrite(str(out_path_chest), boxed_chest)\n",
    "\n",
    "    out_path_abd = out_dir / f\"{p.stem}_abd.png\"\n",
    "    cv2.imwrite(str(out_path_abd), boxed_abd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d93cd85e-5888-4bbd-8245-c35db88e149d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: data/seg_example/flir_seg.png\n",
      "Saved: data/seg_example/gray_seg.png\n",
      "Saved: data/seg_example/olympus_seg.png\n",
      "Saved: data/seg_example/phone_seg.png\n"
     ]
    }
   ],
   "source": [
    "out_dir = Path(\"../data/seg_example\")\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "paths = sorted([p for p in example_dir.glob(\"*\") if p.suffix.lower() in [\".png\", \".jpg\", \".jpeg\"]])\n",
    "\n",
    "for p in paths:\n",
    "    camera = p.stem \n",
    "    img_bgr = cv2.imread(str(p), cv2.IMREAD_COLOR)\n",
    "    if img_bgr is None:\n",
    "        print(\"Could not read:\", p)\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        mask = segment_person_deeplab(img_bgr)\n",
    "    except Exception as e:\n",
    "        print(f\"[{camera}] segmentation failed: {e}\")\n",
    "        continue\n",
    "\n",
    "    seg_overlay = overlay_red_mask(img_bgr, mask, alpha=0.45)\n",
    "\n",
    "    out_path = out_dir / f\"{p.stem}_seg.png\"\n",
    "    cv2.imwrite(str(out_path), seg_overlay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9e57aa-269c-4fdc-b99e-0472dada08e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
